{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SAR4Wildfire_EO_Datacubes_Processing.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/puzhao89/Adversarial_Autoencoder/blob/master/SAR4Wildfire_EO_Datacubes_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SHAc5qbiR8l",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## **D3.2 Prototype for analysis ready Sentinel-1/2 data cubes**\n",
        "\n",
        "This script is written to query, process and export time series earth observation data, including Sentinel-1 C-Band SAR, Sentinel-2 and Landsat-8 multispectral data, with Earth Engine Python API.\n",
        "\n",
        "0. Setup Software libaraies\n",
        "1. Define Study Areas\n",
        "2. EO Data Processing\n",
        "3. Export EO Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MJ4kW1pEhwP",
        "colab_type": "text"
      },
      "source": [
        "# Step 0: Import libraries\n",
        "\n",
        "Authenticate and import as necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neIa46CpciXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cloud authentication.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jat01FEoUMqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import, authenticate and initialize the Earth Engine library.\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1hFdpBQfyhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Folium setup.\n",
        "import folium\n",
        "print(folium.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXsQ2e7ugk3h",
        "colab_type": "text"
      },
      "source": [
        "# Step 1: Define Study Areas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq1uMcdJkDFN",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Wildfire Event"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYA1lxnrgigJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\"\"\"////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\"\"\"\n",
        "\"\"\" ================================================================= Study Areas ==================================================================== \"\"\"\n",
        "\"\"\"////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\"\"\"\n",
        "\n",
        "\"\"\" ==============================> Chuckegg Wildfire (2019) <===============================\"\"\"\n",
        "CA_Chuckegg_roi = (ee.Geometry.Rectangle(\n",
        "    [-118.15516161677635, 58.80344955293542,\n",
        "      -116.58411669490135, 57.78735191577551]))\n",
        "Chuckegg = {\n",
        "    'name': 'Chuckegg',\n",
        "    'roi': CA_Chuckegg_roi,\n",
        "    'crs': 'EPSG:32611',\n",
        "\n",
        "    'startDate': '2019-05-15',  # 2019-05-18\n",
        "    'endDate': '2019-08-20',  # 2019-10-01\n",
        "\n",
        "    'msiExportDates': ['2019-05-21', '2019-05-24', '2019-05-26', '2019-05-28', \n",
        "                        '2019-06-10', '2019-06-17', '2019-06-25', '2019-07-11', '2019-07-15', \n",
        "                        '2019-07-17', '2019-07-20', '2019-08-06', '2019-08-12'],\n",
        "\n",
        "    # MSI\n",
        "    'S2_Master': '2019-05-16',  # good S2 prefire date\n",
        "    'L8_Master': '2019-07-05',  # good L8 prefire date\n",
        "\n",
        "    # SAR\n",
        "    'DSC13': '2017-05-17',\n",
        "    'DSC115': '2017-05-12',  # prefire date\n",
        "    'ASC64': '2017-06-26',\n",
        "    'ASC20': '2017-05-12',\n",
        "    # SAR-orbit\n",
        "    'orbNumList': [20],\n",
        "    'bandList': ['VV', 'VH']\n",
        "}\n",
        "\"\"\" ============================= Elephant Wildfire (2017) =============================== \"\"\"\n",
        "elephant_roi = ee.Geometry.Rectangle([-121.7697, 50.6512, -120.7068, 51.5224])\n",
        "elephant_refPoly = ee.FeatureCollection(\"users/omegazhangpzh/elephant_refPoly\")\n",
        "\n",
        "elephant = {\n",
        "    'name': 'elephant',\n",
        "    'roi': elephant_roi,\n",
        "    'poly': elephant_refPoly,\n",
        "    'crs': 'EPSG: 32610',\n",
        "\n",
        "    'startDate': '2017-07-05',  # 2017-07-07\n",
        "    'endDate': '2017-10-06',  # 2017-10-01\n",
        "\n",
        "    # MSI\n",
        "    'S2_Master': '2017-11-06',  # good S2 prefire date\n",
        "    'L8_Master': '2017-07-05',  # good L8 prefire date\n",
        "\n",
        "    # SAR\n",
        "    'DSC13': '2017-05-17',\n",
        "    'DSC115': '2017-05-12',  # prefire date\n",
        "    'ASC64': '2017-06-26',\n",
        "\n",
        "    # SAR-orbit\n",
        "    'orbitList': ['ASC64'],  # ['DSC13', 'DSC115', 'ASC64']\n",
        "    'bandList': ['VV', 'VH']\n",
        "}\n",
        "\n",
        "\"\"\" ============================= Sydney Wildfire (2019) ======================================= \"\"\"\n",
        "Sydney_roi = (ee.Geometry.Rectangle(\n",
        "    [149.62892366273888, -34.46629366617598,\n",
        "      151.60646272523888, -32.24350555003469]))\n",
        "\n",
        "Sydney_msiExportDateList = ['2019-10-22',  # master\n",
        "      '2019-10-27', '2019-10-28', '2019-11-01', '2019-11-06', '2019-11-11', '2019-11-13', '2019-11-21',\n",
        "      '2019-12-16', '2019-12-21', '2019-12-26', '2019-12-31', '2020-01-05', '2020-01-10',\n",
        "      '2019-12-11',  # a bit cloudy, but still good to use\n",
        "      # '2019-12-15', # not good\n",
        "      ]\n",
        "\n",
        "Sydney_sarExportDateList = ['2019-10-28', '2019-11-06', '2019-11-09', '2019-11-18', '2019-11-21', '2019-11-27',\n",
        "                      '2019-11-30', '2019-12-12', '2019-12-15', '2019-12-24', '2019-12-27', '2020-01-05',\n",
        "                      '2020-01-08']\n",
        "\n",
        "Sydney_AU = {\n",
        "    'name': 'Sydney_small',\n",
        "    'roi': Sydney_roi,  # Sydney_roi_1111,\n",
        "    'poly': Sydney_roi,\n",
        "    'crs': 'EPSG:3577',  # 'EPSG:3577', # EPSG:3577\n",
        "    'pntsRect': (ee.Geometry.Rectangle([150.0941018581052, -34.12241279581038,\n",
        "                                        151.1927346706052, -32.894960055302946])),  # AU\n",
        "\n",
        "    'startDate': '2019-10-22',  # 2018-11-08\n",
        "    'endDate': '2020-01-11',  # 2018-12-10\n",
        "    'msiExportDates': Sydney_msiExportDateList,\n",
        "    'sarExportDates': Sydney_sarExportDateList,\n",
        "\n",
        "    'S2_Master': '2019-10-22',\n",
        "    # 'L8_Master': '2018-11-06',\n",
        "\n",
        "    'ASC9': '2019-10-16',\n",
        "    'DSC147': '2019-10-25',  # prefire date\n",
        "    # 'DSC42': '2018-11-04',\n",
        "    # 'ASC137': '2018-11-05',\n",
        "    #\n",
        "    # 'orbitList': ['ASC35', 'DSC115', 'DSC42', 'ASC137'],\n",
        "    'orbNumList': [9, 147],\n",
        "    'bandList': ['VV', 'VH']\n",
        "}\n",
        "\n",
        "### Karbole Wildfire 2018, Sweden\n",
        "Karbole_roi = ee.Geometry.Rectangle([\n",
        "    15.137434283688016, 61.86566784664094,\n",
        "    15.604353229000516, 62.06961520427164])\n",
        "\n",
        "Karbole_SE = {\n",
        "    'name': 'Karbole_SE',\n",
        "    'roi': Karbole_roi,\n",
        "    'crs': 'EPSG:3006',\n",
        "\n",
        "    'startDate': '2018-07-01',  # 2019-05-18\n",
        "    'endDate': '2018-08-10',  # 2019-10-01\n",
        "    'msExportDates': ['2018-07-16', '2018-07-17','2018-07-19', '2018-07-24','2018-07-26',\n",
        "                      '2018-07-27','2018-07-31','2018-08-03','2018-08-08'],\n",
        "\n",
        "    # MSI Master Dates\n",
        "    'S2_Master': '2018-07-04',  # good S2 prefire date\n",
        "    # 'L8_Master': '2017-07-05',  # good L8 prefire date\n",
        "\n",
        "    # SAR Master Dates\n",
        "    # 'ASC102': '',\n",
        "    'DSC66': '2018-07-09',\n",
        "    'DSC168': '2018-07-10',\n",
        "    'DSC95': '2018-07-11',  # '2018-07-05',\n",
        "\n",
        "    # SAR-orbit\n",
        "    'orbNumList': [66, 168, 95], \n",
        "    'bandList': ['VV', 'VH']\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyQB1yk1jQXX",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Set Global Variable "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pzKxzcujPIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \"\"\"////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\"\"\"\n",
        "# \"\"\" =============================================================== Configuration ==================================================================== \"\"\"\n",
        "# \"\"\"////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\"\"\"\n",
        "\n",
        "fireEvent = Sydney_AU\n",
        "CRS = \"EPSG:4326\" # fireEvent['crs'] #\"EPSG:4326\"  # fireEvent['epsg']#Amazon #\"EPSG:3995\"# Russia  # \"\"EPSG:32610\"\n",
        "\n",
        "\"\"\" Configuration \"\"\"\n",
        "scale = 20\n",
        "cloudLevel = 100 # used for setting cloud level\n",
        "groupLevel = 10  # 2017-04-28T12:12:35(len: 19), 2017-04-28T12(len: 13)\n",
        "labelShowLevel = 10  # IMG_LABEL: if 10 then 2017-04-28 ==> 20170428, if 13 then 20170428T12\n",
        "\n",
        "sarQueryFlag = True # query\n",
        "msiQueryFlag = True\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nt7cATATjd4",
        "colab_type": "text"
      },
      "source": [
        "# Step 2:  EO Datacubes Processing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlENcjKVTG5G",
        "colab_type": "text"
      },
      "source": [
        "### **2.1** Datacube Processing Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POhOP0NUTDxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// \"\"\"\n",
        "\"\"\" /////////////////////////////////////////     Functions for EE Preprocessing     //////////////////////////////////////// \"\"\"\n",
        "\"\"\" ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// \"\"\"\n",
        "\n",
        "import ee, time\n",
        "ee.Initialize()\n",
        "\n",
        "def set_timeEnd_newdays(img):\n",
        "    group_days = img.date().format().slice(0, 10)\n",
        "    return img.set('system:time_end', group_days)\n",
        "\n",
        "\n",
        "\"\"\" SAR Group Days \"\"\"\n",
        "def set_group_index_4_S1(img):\n",
        "    orbitKey = (ee.String(img.get(\"orbitProperties_pass\")).replace('DESCENDING', 'DSC').replace('ASCENDING', 'ASC')\n",
        "                .cat(ee.Number(img.get(\"relativeOrbitNumber_start\")).int().format()))\n",
        "    Date = (img.date().format().slice(0, labelShowLevel).replace('-', '').replace('-', ''))\n",
        "    Name = (Date).cat('_').cat(orbitKey)\n",
        "\n",
        "    groupIndex = img.date().format().slice(0, groupLevel)  # 2017 - 07 - 23T14:11:22(len: 19)\n",
        "    return img.setMulti({\n",
        "        'GROUP_INDEX': groupIndex,\n",
        "        'IMG_LABEL': Name,\n",
        "        'Orbit_Key': orbitKey\n",
        "    })\n",
        "\n",
        "\n",
        "# \"group by\" date\n",
        "def group_S1_by_date_orbit(imgcollection):\n",
        "    imgCol_sort = imgcollection.sort(\"system:time_start\")\n",
        "    imgCol = imgCol_sort.map(set_group_index_4_S1)\n",
        "    d = imgCol.distinct(['GROUP_INDEX'])\n",
        "    di = ee.ImageCollection(d)\n",
        "    date_eq_filter = (ee.Filter.equals(leftField='system:time_end',\n",
        "                                       rightField='system:time_end'))\n",
        "\n",
        "    date_eq_filter = (ee.Filter.And(\n",
        "        ee.Filter.equals(leftField='GROUP_INDEX', rightField='GROUP_INDEX')\n",
        "        , ee.Filter.equals(leftField='Orbit_Key', rightField='Orbit_Key')\n",
        "        , ee.Filter.equals(leftField='transmitterReceiverPolarisation', rightField='transmitterReceiverPolarisation')\n",
        "    ))\n",
        "\n",
        "    saveall = ee.Join.saveAll(\"to_mosaic\")\n",
        "    j = saveall.apply(di, imgCol, date_eq_filter)\n",
        "    ji = ee.ImageCollection(j)\n",
        "\n",
        "    def mosaicImageBydate(img):\n",
        "        ## Old version\n",
        "        # mosaiced = ee.ImageCollection.fromImages(img.get('to_mosaic')).mosaic().updateMask(1)\n",
        "        # return ee.Image(mosaiced).copyProperties(img, img.propertyNames())\n",
        "\n",
        "        imgCol2mosaic = ee.ImageCollection.fromImages(img.get('to_mosaic'))\n",
        "        firstImgGeom = imgCol2mosaic.first().geometry()\n",
        "        mosaicGeom = ee.Geometry(imgCol2mosaic.iterate(unionGeomFun, firstImgGeom))\n",
        "        mosaiced = imgCol2mosaic.mosaic().copyProperties(img, img.propertyNames())\n",
        "        return ee.Image(mosaiced).set(\"system:footprint\", mosaicGeom)  # lost\n",
        "\n",
        "    imgcollection_grouped = ji.map(mosaicImageBydate)\n",
        "    return ee.ImageCollection(imgcollection_grouped.copyProperties(imgCol, imgCol.propertyNames()))\n",
        "\n",
        "\n",
        "def add_RBR(img):\n",
        "    RBR = img.expression('b(\"VH\")-b(\"VV\")').rename(\"RBR\")  # (b(\"VV\")-b(\"VH\"))/(b(\"VV\")+b(\"VH\"))\n",
        "    return ee.Image(img.addBands(RBR).copyProperties(img, img.propertyNames()))\n",
        "\n",
        "\n",
        "def printList(inList, markString=None):\n",
        "    print(\"---------{}: {}----------\".format(markString, len(inList)))\n",
        "    for ele in inList:\n",
        "        print(ele)\n",
        "    print(\"---------------------\\n\")\n",
        "\n",
        "\n",
        "\"\"\" Preprocessing Funs for MS Images \"\"\"\n",
        "\n",
        "\n",
        "def S2_bandRename(img):\n",
        "    toBandNameList = ['B', 'G', 'R', 'NIR', 'SWIR1', 'SWIR2', 'cloud']\n",
        "    return (img.select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12', 'QA60'])\n",
        "            .rename(toBandNameList).copyProperties(img, img.propertyNames()))\n",
        "\n",
        "\n",
        "def L8_bandRename(img):\n",
        "    toBandNameList = ['B', 'G', 'R', 'NIR', 'SWIR1', 'SWIR2', 'cloud']\n",
        "    # toBandNameList = ['B2', 'B3', 'B4', 'NIR', 'B11', 'B12', 'cloud']\n",
        "    return (img.select(['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'BQA'])\n",
        "            .rename(toBandNameList).copyProperties(img, img.propertyNames()))\n",
        "\n",
        "\n",
        "def add_NDVI(img):\n",
        "    NDVI = img.normalizedDifference(['NIR', 'R']).select('nd').rename('NDVI')\n",
        "    return img.addBands(NDVI).copyProperties(img, img.propertyNames())\n",
        "\n",
        "\n",
        "def add_NBR(img):\n",
        "    NBR = img.normalizedDifference(['NIR', 'SWIR2']).select('nd').rename('NBR')\n",
        "    NBR1 = img.normalizedDifference(['SWIR1', 'SWIR2']).select('nd').rename('NBR1')\n",
        "    return img.addBands(NBR).addBands(NBR1).copyProperties(img, img.propertyNames())\n",
        "\n",
        "\n",
        "def updateCloudMaskL8(img):\n",
        "    qa = img.select('cloud')  # BQA\n",
        "    mask = qa.bitwiseAnd(1 << 4).eq(0)\n",
        "    return img.addBands(mask, overwrite=True) # 0 for cloud, 1 for clear\n",
        "\n",
        "def updateCloudMaskS2(img):\n",
        "    qa = img.select('cloud')  # QA60\n",
        "    cloudBitMask = 1 << 10\n",
        "    cirrusBitMask = 1 << 11\n",
        "    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(\n",
        "        qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
        "    return img.addBands(mask, overwrite=True)\n",
        "\n",
        "def mask_L8_clouds(img):\n",
        "    return img.updateMask(updateCloudMaskL8(img).select('cloud'))\n",
        "\n",
        "def mask_S2_clouds(img):\n",
        "    return img.updateMask(updateCloudMaskS2(img).select('cloud'))\n",
        "\n",
        "\n",
        "# def maskClouds(image):\n",
        "#     score = image.select('cloud')  # S2: QA60\n",
        "#     mask = score.lt(1)\n",
        "#     return image.updateMask(mask).copyProperties(image, image.propertyNames())\n",
        "#\n",
        "#\n",
        "# def L8_cloud_div10(img):\n",
        "#     return img.addBands(srcImg=ee.Image(img).select('cloud').divide(10),\n",
        "#                         overwrite=True)\n",
        "\n",
        "\n",
        "\"\"\" ====================== Sentinel-2 ======================\"\"\"\n",
        "\n",
        "\n",
        "def set_S2_group_index(img):\n",
        "    imgDateStr = img.date().format()\n",
        "\n",
        "    groupIndex = imgDateStr.slice(0, groupLevel)  # 2017 - 07 - 23 T14:11:22(len: 19)\n",
        "\n",
        "    Date = imgDateStr.slice(0, labelShowLevel).replace('-', '').replace('-', '')\n",
        "\n",
        "    imgLabel = (Date).cat(\"_S2\")\n",
        "\n",
        "    return img.setMulti({\n",
        "        'GROUP_INDEX': groupIndex,\n",
        "        'SAT_NAME': 'S2',\n",
        "        'IMG_LABEL': imgLabel\n",
        "    })\n",
        "\n",
        "\n",
        "def unionGeomFun(img, first):\n",
        "    rightGeo = ee.Geometry(img.geometry())\n",
        "    return ee.Geometry(first).union(rightGeo)\n",
        "\n",
        "\n",
        "# \"group by date\n",
        "def group_S2_ImgCol(imgcollection, multiSensorGroupFlag=False):\n",
        "    imgCol_sort = imgcollection.sort(\"system:time_start\")\n",
        "    imgCol = imgCol_sort.map(set_S2_group_index)\n",
        "\n",
        "    d = imgCol.distinct(['GROUP_INDEX'])\n",
        "    di = ee.ImageCollection(d)\n",
        "\n",
        "    # Join collection to itself grouped by date\n",
        "    date_eq_filter = ee.Filter.And(\n",
        "        ee.Filter.equals(leftField='GROUP_INDEX', rightField='GROUP_INDEX')\n",
        "        , ee.Filter.equals(leftField='SAT_NAME', rightField='SAT_NAME'))\n",
        "\n",
        "    if (multiSensorGroupFlag):  # if it is allowed to group data from multiple sensor.\n",
        "        date_eq_filter = ee.Filter.equals(leftField='GROUP_INDEX', rightField='GROUP_INDEX')\n",
        "\n",
        "    saveall = ee.Join.saveAll(\"to_mosaic\")\n",
        "    j = saveall.apply(di, imgCol, date_eq_filter)\n",
        "    ji = ee.ImageCollection(j)\n",
        "\n",
        "    original_proj = ee.Image(ji.first()).select(0).projection()\n",
        "\n",
        "    def mosaicImageBydate(img):\n",
        "        ## Old version\n",
        "        # mosaiced = ee.ImageCollection.fromImages(img.get('to_mosaic')).mosaic().updateMask(1)\n",
        "        # return ee.Image(mosaiced).copyProperties(img, img.propertyNames())\n",
        "\n",
        "        imgCol2mosaic = ee.ImageCollection.fromImages(img.get('to_mosaic'))\n",
        "        firstImgGeom = imgCol2mosaic.first().geometry()\n",
        "        mosaicGeom = ee.Geometry(imgCol2mosaic.iterate(unionGeomFun, firstImgGeom))\n",
        "        mosaiced = imgCol2mosaic.mosaic().copyProperties(img, img.propertyNames())\n",
        "        return ee.Image(mosaiced).set(\"system:footprint\", mosaicGeom)  # lost\n",
        "\n",
        "    imgcollection_grouped = ji.map(mosaicImageBydate)\n",
        "    return ee.ImageCollection(imgcollection_grouped.copyProperties(imgCol, imgCol.propertyNames()))\n",
        "\n",
        "\n",
        "\"\"\"// // / == == == == == == == == Grouping Landsat-8 ImageCollections == == == == == == == == ==\"\"\"\n",
        "\n",
        "\n",
        "def set_L8_group_index(img):\n",
        "    imgDateStr = img.date().format()\n",
        "    groupIndex = imgDateStr.slice(0, groupLevel)  # 2017 - 07 - 23T14:11:22(len: 19)\n",
        "\n",
        "    Date = imgDateStr.slice(0, labelShowLevel).replace('-', '').replace('-', '')\n",
        "\n",
        "    imgLabel = (Date).cat(\"_L8\")\n",
        "\n",
        "    return img.setMulti({\n",
        "        'GROUP_INDEX': groupIndex,\n",
        "        'SAT_NAME': 'L8',\n",
        "        'IMG_LABEL': imgLabel\n",
        "    })\n",
        "\n",
        "\n",
        "# \"group by date\n",
        "def group_L8_ImgCol(imgcollection, multiSensorGroupFlag=False):\n",
        "    imgCol_sort = imgcollection.sort(\"system:time_start\")\n",
        "    imgCol = imgCol_sort.map(set_L8_group_index)\n",
        "\n",
        "    d = imgCol.distinct(['GROUP_INDEX'])\n",
        "    di = ee.ImageCollection(d)\n",
        "\n",
        "    # Join collection to itself grouped by date\n",
        "    date_eq_filter = ee.Filter.And(\n",
        "        ee.Filter.equals(leftField='GROUP_INDEX', rightField='GROUP_INDEX')\n",
        "        , ee.Filter.equals(leftField='SAT_NAME', rightField='SAT_NAME'))\n",
        "\n",
        "    if (multiSensorGroupFlag):  # if it is allowed to group data from multiple sensor.\n",
        "        date_eq_filter = ee.Filter.equals(leftField='GROUP_INDEX', rightField='GROUP_INDEX')\n",
        "\n",
        "    saveall = ee.Join.saveAll(\"to_mosaic\")\n",
        "    j = saveall.apply(di, imgCol, date_eq_filter)\n",
        "    ji = ee.ImageCollection(j)\n",
        "\n",
        "    original_proj = ee.Image(ji.first()).select(0).projection()\n",
        "\n",
        "    def mosaicImageBydate(img):\n",
        "        ## Old version\n",
        "        # mosaiced = ee.ImageCollection.fromImages(img.get('to_mosaic')).mosaic().updateMask(1)\n",
        "        # return ee.Image(mosaiced).copyProperties(img, img.propertyNames())\n",
        "\n",
        "        imgCol2mosaic = ee.ImageCollection.fromImages(img.get('to_mosaic'))\n",
        "        firstImgGeom = imgCol2mosaic.first().geometry()\n",
        "        mosaicGeom = ee.Geometry(imgCol2mosaic.iterate(unionGeomFun, firstImgGeom))\n",
        "        mosaiced = imgCol2mosaic.mosaic().copyProperties(img, img.propertyNames())\n",
        "        return ee.Image(mosaiced).set(\"system:footprint\", mosaicGeom)  # lost\n",
        "\n",
        "    imgcollection_grouped = ji.map(mosaicImageBydate)\n",
        "    return ee.ImageCollection(imgcollection_grouped.copyProperties(imgCol, imgCol.propertyNames()))\n",
        "\n",
        "\"\"\" ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// \"\"\"\n",
        "\"\"\" /////////////////////////////////////////     Functions for Exporting Data from EE     ////////////////////////////////// \"\"\"\n",
        "\"\"\" ///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// \"\"\"\n",
        "\n",
        "def check_export_task(task, imgName):\n",
        "    # Block until the task completes.\n",
        "    print('Running export from GEE to drive or cloudStorage...')\n",
        "    while task.active():\n",
        "        time.sleep(30)\n",
        "\n",
        "    # Error condition\n",
        "    if task.status()['state'] != 'COMPLETED':\n",
        "        print(\"Error with export: {}\".format(imgName))\n",
        "    else:\n",
        "        print(\"Export completed: {}\".format(imgName))\n",
        "\n",
        "def batch_imgCol_export_to_drive(imgCol, N=100, KERNEL_SIZE=256, bands4download=[''], toDriveFolder=\"Sydney_tfRecord\"):\n",
        "    print(\"------------------------- Download Start ... ----------------------------------\")\n",
        "    downLoadList = (imgCol).aggregate_array('IMG_LABEL').getInfo()\n",
        "    printList(downLoadList, 'downloadList: ')\n",
        "\n",
        "    # KERNEL_SIZE = 256R\n",
        "    n = 10\n",
        "    # N = 100\n",
        "    list = ee.List.repeat(1, KERNEL_SIZE)\n",
        "    lists = ee.List.repeat(list, KERNEL_SIZE)\n",
        "    kernel = ee.Kernel.fixed(KERNEL_SIZE, KERNEL_SIZE, lists)\n",
        "\n",
        "    num = imgCol.size().getInfo()\n",
        "    imgColList = imgCol.toList(num)\n",
        "\n",
        "    for i in range(0, num):\n",
        "        img = ee.Image(imgColList.get(i))\n",
        "        imgName = img.get('IMG_LABEL').getInfo().replace(\":\", '')\n",
        "\n",
        "        arrays = img.neighborhoodToArray(kernel)\n",
        "        featCol = ee.FeatureCollection([])\n",
        "        for SEED in range(n):\n",
        "            tmpfeatCol = arrays.sample(\n",
        "                region=roi,\n",
        "                scale=20,\n",
        "                numPixels=N / n,\n",
        "                seed=SEED,\n",
        "                tileScale=8).select(bands4download)\n",
        "            featCol = featCol.merge(tmpfeatCol)\n",
        "\n",
        "        task = ee.batch.Export.table.toDrive(\n",
        "            collection=featCol,\n",
        "            description=\"{}_ks{}_N{}\".format(imgName, KERNEL_SIZE, featCol.size().getInfo()),\n",
        "            folder=toDriveFolder,\n",
        "            fileNamePrefix=\"{}_ks{}_N{}\".format(imgName, KERNEL_SIZE, featCol.size().getInfo()),\n",
        "            fileFormat=\"TFRecord\")\n",
        "\n",
        "        task.start()\n",
        "        check_export_task(task, imgName)\n",
        "\n",
        "def batch_imgCol_export_to_cloud(imgCol, N=100, KERNEL_SIZE=256, toDriveFolder=\"Sydney_NRT_roi\"):\n",
        "    print(\"------------------------- Download Start ... ----------------------------------\")\n",
        "    downLoadList = (imgCol).aggregate_array('IMG_LABEL').getInfo()\n",
        "    printList(downLoadList, 'downloadList: ')\n",
        "\n",
        "    # KERNEL_SIZE = 256R\n",
        "    n = 1\n",
        "    # N = 100\n",
        "    list = ee.List.repeat(1, KERNEL_SIZE)\n",
        "    lists = ee.List.repeat(list, KERNEL_SIZE)\n",
        "    kernel = ee.Kernel.fixed(KERNEL_SIZE, KERNEL_SIZE, lists)\n",
        "\n",
        "    num = imgCol.size().getInfo()\n",
        "    imgColList = imgCol.toList(num)\n",
        "\n",
        "    for i in range(0, num):\n",
        "        img = ee.Image(imgColList.get(i))\n",
        "        imgName = img.get('IMG_LABEL').getInfo().replace(\":\", '')\n",
        "\n",
        "        arrays = img.neighborhoodToArray(kernel)\n",
        "        featCol = ee.FeatureCollection([])\n",
        "        for SEED in range(n):\n",
        "            tmpfeatCol = arrays.sample(\n",
        "                region=roi,\n",
        "                scale=20,\n",
        "                numPixels=N / n,\n",
        "                seed=SEED,\n",
        "                tileScale=8)\n",
        "\n",
        "            featCol = featCol.merge(tmpfeatCol)\n",
        "\n",
        "        desc = \"{}_ks{}_N{}\".format(imgName, KERNEL_SIZE, featCol.size().getInfo()),\n",
        "        task = ee.batch.Export.table.toCloudStorage(\n",
        "            collection=featCol,\n",
        "            description=desc,\n",
        "            bucket=BUCKET,\n",
        "            folder=toDriveFolder + \"/\" + desc,\n",
        "            fileNamePrefix=desc,\n",
        "            fileFormat=\"TFRecord\",\n",
        "            selectors=BANDS\n",
        "        )\n",
        "\n",
        "        task.start()\n",
        "        check_export_task(task, imgName)\n",
        "\n",
        "    \n",
        "def buildGeometryPoint(pnt):\n",
        "    return pnt.setGeometry(ee.Geometry.Point([pnt.get(\"longitude\"), pnt.get(\"latitude\")]))\n",
        "\n",
        "def batch_imgCol_export_to_cloud_classBalanced(imgCol, classBand, N=100, KERNEL_SIZE=256, toDriveFolder=\"Sydney_NRT\"):\n",
        "    print(\"------------------------- Download Start ... ----------------------------------\")\n",
        "    downLoadList = (imgCol).aggregate_array('IMG_LABEL').getInfo()\n",
        "    printList(downLoadList, 'to_cloud_classBalanced')\n",
        "\n",
        "    # KERNEL_SIZE = 256R\n",
        "    n = 30\n",
        "    # N = 100\n",
        "    list = ee.List.repeat(1, KERNEL_SIZE)\n",
        "    lists = ee.List.repeat(list, KERNEL_SIZE)\n",
        "    kernel = ee.Kernel.fixed(KERNEL_SIZE, KERNEL_SIZE, lists)\n",
        "\n",
        "    num = imgCol.size().getInfo()\n",
        "    imgColList = imgCol.toList(num)\n",
        "\n",
        "    for i in range(0, num):\n",
        "        img = ee.Image(imgColList.get(i))\n",
        "        imgName = img.get('IMG_LABEL').getInfo().replace(\":\", '')\n",
        "  \n",
        "        arrays = img.neighborhoodToArray(kernel)\n",
        "        featCol = ee.FeatureCollection([])\n",
        "        for SEED in range(n):\n",
        "            # print(\"SEED: {}\".format(SEED))\n",
        "            pntCol = (img.select(classBand).rename('class').toInt().addBands(ee.Image.pixelLonLat())\n",
        "                .stratifiedSample(\n",
        "                    region=roi,\n",
        "                    numPoints=int(N/n),\n",
        "                    classBand='class',\n",
        "                    scale=20,\n",
        "                    seed=SEED,\n",
        "                    dropNulls=True,\n",
        "                    tileScale=8\n",
        "                ).map(buildGeometryPoint)\n",
        "            )  \n",
        "\n",
        "            tmpfeatCol = arrays.sampleRegions(\n",
        "              collection=pntCol,\n",
        "              scale=20,\n",
        "              # properties=FEATURES,\n",
        "              tileScale=8\n",
        "            )\n",
        "\n",
        "            print(\"SEED {}: {}\".format(SEED, tmpfeatCol.size().getInfo()))\n",
        "            featCol = featCol.merge(tmpfeatCol)\n",
        "\n",
        "        desc = \"trainPatches_{}_ks{}_N{}\".format(imgName, KERNEL_SIZE, featCol.size().getInfo())\n",
        "        print(\"desc: {}\".format(desc))\n",
        "        task = ee.batch.Export.table.toDrive(\n",
        "            collection=featCol,\n",
        "            description=desc,\n",
        "            # bucket=BUCKET,\n",
        "            folder=toDriveFolder,\n",
        "            fileNamePrefix=desc,\n",
        "            fileFormat=\"TFRecord\",\n",
        "            selectors=FEATURES\n",
        "        )\n",
        "\n",
        "        task.start()\n",
        "        check_export_task(task, desc)\n",
        "\n",
        "def batch_imgCol_export_to_drive_by_pntCol(imgCol, pntCol, KERNEL_SIZE=256, bands4download=[''], toDriveFolder=''):\n",
        "    print(\"------------------------- Download Start ... ----------------------------------\")\n",
        "    downLoadList = (imgCol).aggregate_array('IMG_LABEL').getInfo()\n",
        "    printList(downLoadList, 'downloadList')\n",
        "\n",
        "    # KERNEL_SIZE = 256R\n",
        "    # n = 10\n",
        "    # N = 1000\n",
        "    list = ee.List.repeat(1, KERNEL_SIZE)\n",
        "    lists = ee.List.repeat(list, KERNEL_SIZE)\n",
        "    kernel = ee.Kernel.fixed(KERNEL_SIZE, KERNEL_SIZE, lists)\n",
        "\n",
        "    num = imgCol.size().getInfo()\n",
        "    imgColList = imgCol.toList(num)\n",
        "\n",
        "    for i in range(0, num):\n",
        "        img = ee.Image(imgColList.get(i))\n",
        "        imgName = img.get('IMG_LABEL').getInfo().replace(\":\", '')\n",
        "\n",
        "        arrays = img.select(bands4download).neighborhoodToArray(kernel)\n",
        "        featCol = arrays.sampleRegions(\n",
        "            collection=pntCol,\n",
        "            scale=20,\n",
        "            # properties=bands4download,\n",
        "            tileScale=8\n",
        "        )\n",
        "\n",
        "        task = ee.batch.Export.table.toDrive(\n",
        "            collection=featCol,\n",
        "            description=\"{}_ks{}_N{}_by_pntCol\".format(imgName, KERNEL_SIZE, featCol.size().getInfo()),\n",
        "            folder=\"{}_by_pntCol\".format(toDriveFolder),\n",
        "            fileNamePrefix=\"{}_ks{}_N{}_by_pntCol\".format(imgName, KERNEL_SIZE, featCol.size().getInfo()),\n",
        "            fileFormat=\"TFRecord\")\n",
        "\n",
        "        task.start()\n",
        "        check_export_task(task, imgName)\n",
        "\n",
        "\n",
        "def export_img_time_series_by_AOI(imgCol, pntCol, KERNEL_SIZE=256, BANDS=[], toFolder='', fileFormat='TFRecord'):\n",
        "    print(\"------------------------- Download Start ... ----------------------------------\")\n",
        "    downLoadList = (imgCol).aggregate_array('IMG_LABEL').getInfo()\n",
        "    printList(downLoadList, ' aoi_time_series ')\n",
        "\n",
        "    list = ee.List.repeat(1, KERNEL_SIZE)\n",
        "    lists = ee.List.repeat(list, KERNEL_SIZE)\n",
        "    kernel = ee.Kernel.fixed(KERNEL_SIZE, KERNEL_SIZE, lists)\n",
        "\n",
        "    def set_aoi_id(pnt):\n",
        "        return pnt.set('aoi', pnt.id())\n",
        "\n",
        "    def sampleOverImage(img):\n",
        "        def setImgLabel(f):\n",
        "            return f.set('IMG_LABEL', img.get(\"IMG_LABEL\"))\n",
        "\n",
        "        return (img.select(BANDS).float()\n",
        "                .neighborhoodToArray(kernel)\n",
        "                .sampleRegions(\n",
        "            collection=pntCol,\n",
        "            scale=20,\n",
        "            # properties=bands4download,\n",
        "            tileScale=8\n",
        "        ).map(setImgLabel))\n",
        "\n",
        "    def formatData(table, rowId, colId):\n",
        "        rows = table.distinct(rowId)\n",
        "        joined = ee.Join.saveAll('matches').apply(\n",
        "            primary=rows,\n",
        "            secondary=table,\n",
        "            condition=ee.Filter.equals(\n",
        "                leftField=rowId,\n",
        "                rightField=rowId\n",
        "            ))\n",
        "\n",
        "        def prepareData(row):\n",
        "            # def bandConCat(BANDS):\n",
        "\n",
        "            def data2array(feat):\n",
        "                feat = ee.Feature(feat)\n",
        "                array = ee.Array.cat(\n",
        "                    [ee.Array(feat.get('NIR')), ee.Array(feat.get('SWIR1')), ee.Array(feat.get('SWIR2')),\n",
        "                     ee.Array(feat.get('dNBR1'))])\n",
        "                return [feat.get(colId), array]\n",
        "\n",
        "            values = ee.List(row.get('matches')).map(data2array)\n",
        "            return row.select([rowId]).set(ee.Dictionary(values.flatten()))\n",
        "\n",
        "        return joined.map(prepareData)\n",
        "\n",
        "    pntCol = pntCol.map(set_aoi_id)\n",
        "    triplets = imgCol.map(sampleOverImage).flatten()\n",
        "    featCol = formatData(triplets, 'aoi', 'IMG_LABEL')\n",
        "\n",
        "    desc = \"{}_ks{}_N{}_by_pntCol_TFRecord\".format('aoi_time_series', KERNEL_SIZE, featCol.size().getInfo())\n",
        "    task = ee.batch.Export.table.toDrive(\n",
        "        collection=featCol,\n",
        "        description=desc,\n",
        "        folder=\"{}_by_pntCol\".format(toFolder),\n",
        "        fileNamePrefix=desc,\n",
        "        # fileFormat=fileFormat\n",
        "        fileFormat=\"TFRecord\"\n",
        "    )\n",
        "\n",
        "    task.start()\n",
        "    check_export_task(task, desc)\n",
        "\n",
        "\n",
        "\n",
        "def export_imgCol_to_Cloud_by_patch(imgCol, KERNEL_SIZE=256, BANDS=[], fileFormat='GeoTIFF'):\n",
        "    print(\"------------------------- Download Start ... ----------------------------------\")\n",
        "    downLoadList = (imgCol).aggregate_array('IMG_LABEL').getInfo()\n",
        "    printList(downLoadList, ' aoi_time_series ')\n",
        "\n",
        "    num = imgCol.size().getInfo()\n",
        "    imgColList = imgCol.toList(num)\n",
        "\n",
        "    for i in range(0, num):\n",
        "        img = ee.Image(imgColList.get(i))\n",
        "        imgName = img.get('IMG_LABEL').getInfo().replace(\":\", '')\n",
        "\n",
        "        task = ee.batch.Export.image.toCloudStorage(\n",
        "            image=img.select(BANDS),\n",
        "            description=\"{}_{}\".format(fireEvent['name'], imgName),\n",
        "            bucket=BUCKET,\n",
        "            # folder=\"{}/{}\".format(fireEvent['name'], imgName),\n",
        "            fileNamePrefix='{}/{}'.format(\"{}/{}\".format(fireEvent['name'], imgName), imgName),\n",
        "            scale=20,\n",
        "            region=roi,\n",
        "            maxPixels=1e10,\n",
        "            fileFormat='TFRecord',\n",
        "            # shardSize=KERNEL_SIZE,\n",
        "            # fileDimensions=KERNEL_SIZE,\n",
        "            formatOptions={\n",
        "                'patchDimensions': [KERNEL_SIZE, KERNEL_SIZE],\n",
        "                'kernelSize': [128, 128],\n",
        "                'compressed': True,\n",
        "                'maxFileSize': 104857600 # 1024*1024\n",
        "            }\n",
        "        )\n",
        "        task.start()\n",
        "        check_export_task(task, imgName)\n",
        "\n",
        "\"\"\" Transform image to poly \"\"\"\n",
        "def img2poly(img0):\n",
        "    img = img0.reduce(ee.Reducer.anyNonZero())\n",
        "    poly = img.reduceToVectors(\n",
        "        geometry=img.geometry(),\n",
        "        scale=50,\n",
        "        maxPixels=1361828260)\n",
        "    return ee.FeatureCollection(poly)\n",
        "\n",
        "\n",
        "def exportPolyToAsset(burnRef):\n",
        "    imgLabel = burnRef.get('IMG_LABEL').getInfo()\n",
        "    unburnRef = burnRef.mask(burnRef.neq(1).And(waterMask0.neq(0))).eq(0).clip(roi)\n",
        "\n",
        "    polys = {}\n",
        "    polys['polyBurnt'] = img2poly(burnRef.mask(burnRef.eq(1)))\n",
        "    polys['polyUnburn'] = img2poly(unburnRef.mask(unburnRef.eq(1)))\n",
        "\n",
        "    for polyKey in ['polyUnburn']:\n",
        "        assetId = \"users/omegazhangpzh/Sydney_polys/{}\".format(imgLabel)\n",
        "        task = ee.batch.Export.table.toAsset(\n",
        "            collection=polys[polyKey],\n",
        "            description=\"{}_{}\".format(imgLabel, polyKey),\n",
        "            assetId=\"{}_{}\".format(assetId, polyKey))\n",
        "\n",
        "        task.start()\n",
        "        check_export_task(task, \"{}_poly\".format(imgLabel))\n",
        "\n",
        "def exportImageToAsset(burnRef):\n",
        "    imgLabel = burnRef.get('IMG_LABEL').getInfo()\n",
        "\n",
        "    assetId = \"users/omegazhangpzh/Sydney_polys/{}\".format(imgLabel)\n",
        "    task = ee.batch.Export.image.toAsset(\n",
        "        image=burnRef,\n",
        "        description=\"{}\".format(imgLabel),\n",
        "        assetId=\"{}\".format(assetId),\n",
        "        scale=20,\n",
        "        # maxPixels=1784780954588439758\n",
        "    )\n",
        "\n",
        "    task.start()\n",
        "    check_export_task(task, \"{}_toAsset\".format(imgLabel))\n",
        "\n",
        "def filt_morph(img):\n",
        "    kernel_slope = ee.Kernel.gaussian(radius=2)\n",
        "    kernel_slope2 = ee.Kernel.gaussian(radius=1)\n",
        "    return (img.focal_median(kernel=kernel_slope, iterations=1)\n",
        "            .focal_max(kernel=kernel_slope2, iterations=1)\n",
        "            .focal_min(kernel=kernel_slope2, iterations=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncibVgjzT13f",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Start to Query and Process Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9DHe4AjGpk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "fireName = fireEvent['name']\n",
        "roi = fireEvent['roi']\n",
        "\n",
        "fireStartDate = fireEvent['startDate']\n",
        "fireEndDate = fireEvent['endDate']\n",
        "\n",
        "''' Point Filter '''\n",
        "pntsFilterFlag = False\n",
        "if 'pntsRect' in fireEvent.keys():\n",
        "    pntsFilterFlag = True\n",
        "    pntsRect = fireEvent['pntsRect']\n",
        "    coordList = ee.List(roi.coordinates().get(0))\n",
        "    p0 = ee.Geometry.Point(coordList.get(0))  # Bottom-Left\n",
        "    p1 = ee.Geometry.Point(coordList.get(1))  # Bottom-Right\n",
        "    p2 = ee.Geometry.Point(coordList.get(2))  # Top-Right\n",
        "    p3 = ee.Geometry.Point(coordList.get(3))  # Top-Left\n",
        "    pntsFilter = ee.Filter.And(\n",
        "        ee.Filter.geometry(p0)\n",
        "        # , ee.Filter.geometry(p1)\n",
        "        # , ee.Filter.geometry(p2)\n",
        "        # , ee.Filter.geometry(p3)\n",
        "    )\n",
        "\n",
        "quaryROI = roi\n",
        "G_kernel = ee.Kernel.gaussian(21)\n",
        "\n",
        "''' SAR '''\n",
        "sarKmapFlag = True & sarQueryFlag  # kmap flag\n",
        "sarLogRtExportFlag = True & sarQueryFlag\n",
        "\n",
        "\n",
        "''' MSI '''\n",
        "msiExportFlag = True & msiQueryFlag\n",
        "\n",
        "checkStartDate = ee.Date(fireStartDate)\n",
        "checkEndDate = ee.Date(fireEndDate)\n",
        "\n",
        "print(\"==================> {}: [ {}, {} ] <=================\".format(fireEvent['name'], fireStartDate, fireEndDate))\n",
        "print(\" Checking: [ {}, {} ]\".format(checkStartDate.format().getInfo(), checkEndDate.format().getInfo()))\n",
        "print(\"==================================================================\")\n",
        "\n",
        "\"\"\" Dates to Export \"\"\"\n",
        "if 'msiExportDates' in fireEvent.keys():\n",
        "    msiExportDates = fireEvent['msiExportDates']\n",
        "\n",
        "if 'sarExportDates' in fireEvent.keys():\n",
        "    sarExportDates = fireEvent['sarExportDates']\n",
        "\n",
        "\"\"\"======================== DEM ============================\"\"\"\n",
        "hansenImage = ee.Image('UMD/hansen/global_forest_change_2015')\n",
        "datamask = hansenImage.select('datamask')\n",
        "waterMask0 = datamask.eq(1).rename('water')\n",
        "\n",
        "\"\"\" =============== Froest Land Cover 2015 ================= \"\"\"\n",
        "CGLC_2015 = ee.Image(\"COPERNICUS/Landcover/100m/Proba-V/Global/2015\")\n",
        "froestMask = CGLC_2015.select(\"discrete_classification\").eq(112)\n",
        "\n",
        "dem_30m = ee.Image(\"USGS/SRTMGL1_003\")\n",
        "dem = ee.Terrain.products(dem_30m)\n",
        "\n",
        "alos_dem = ee.Image(\"JAXA/ALOS/AW3D30_V1_1\").select('AVE')\n",
        "terrain = ee.Terrain.products(alos_dem)\n",
        "slope = terrain.select(\"slope\")\n",
        "aspect = terrain.select(\"aspect\")\n",
        "hillshade = terrain.select(\"hillshade\")\n",
        "\n",
        "ascMask = filt_morph(ee.Image(1).subtract(ee.Image(slope.gt(20)).multiply(hillshade.gt(180))).rename(\"ASC\"))\n",
        "dscMask = filt_morph(ee.Image(1).subtract(ee.Image(slope.gt(20)).multiply(hillshade.lt(180))).rename(\"DSC\"))\n",
        "# ASC.addBands(DSC)\n",
        "waterMask = ee.Image((waterMask0.addBands(ascMask).addBands(dscMask)).setMulti({'IMG_LABEL': 'waterMask'}))\n",
        "\n",
        "maskDict = {}\n",
        "maskDict['ASC'] = ee.Image(waterMask0.multiply(ascMask))\n",
        "maskDict['DSC'] = ee.Image(waterMask0.multiply(dscMask))\n",
        "\n",
        "# dem\n",
        "\n",
        "# \"\"\"////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\"\"\"\n",
        "# \"\"\" ====================================================== Sentinel-1 C-Band Data ==================================================================== \"\"\"\n",
        "# \"\"\"////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\"\"\"\n",
        "\n",
        "if sarQueryFlag:\n",
        "    print(\"\\n----------------- Sentinel-1 ------------------------\")\n",
        "    S1_filtered = ee.ImageCollection(ee.ImageCollection(\"COPERNICUS/S1_GRD\")\n",
        "                                      .filterBounds(quaryROI)\n",
        "                                      .filterMetadata('instrumentMode', \"equals\", 'IW')\n",
        "                                    #  .filterMetadata('relativeOrbitNumber_start', 'not_equals', 102)\n",
        "                                    #  .filterMetadata('relativeOrbitNumber_start', 'not_equals', 137) # elephant\n",
        "                                    #  .filterMetadata('relativeOrbitNumber_start', 'not_equals', 166) # elephant\n",
        "                                      .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
        "                                      .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\n",
        "                                      )\n",
        "\n",
        "    if 'orbNumList' in fireEvent.keys():\n",
        "        orbNumList = fireEvent['orbNumList']\n",
        "        S1_filtered = S1_filtered.filter(ee.Filter.inList(opt_leftField='relativeOrbitNumber_start', opt_rightValue=orbNumList))\n",
        "\n",
        "    sarImgCol = S1_filtered.filterDate(checkStartDate, checkEndDate)\n",
        "    sarImgCol_grouped = (group_S1_by_date_orbit(sarImgCol)\n",
        "                          .map(add_RBR)\n",
        "                          .select([0, 1, 3])\n",
        "                          )\n",
        "\n",
        "\n",
        "    def sarRescaleToOne(img):\n",
        "        return (ee.Image(img.select(['VV', 'VH', 'RBR'])\n",
        "                          .clamp(-25.0, 5.0).unitScale(-25.0, 5.0).float())\n",
        "                          .copyProperties(img, img.propertyNames())\n",
        "                )\n",
        "\n",
        "\n",
        "    sarImgCol_grouped = sarImgCol_grouped.map(sarRescaleToOne)\n",
        "\n",
        "    print(\"SAR dateRange: [\" + checkStartDate.format().slice(0, 10).getInfo() + \", \"\n",
        "          + checkEndDate.format().slice(0, 10).getInfo() + \"]\")\n",
        "\n",
        "    print('sarImgCol_grouped: ')\n",
        "    printList(sarImgCol_grouped.aggregate_array('IMG_LABEL').getInfo())\n",
        "\n",
        "    # \"\"\"#= == == == == == == == == == == == == == == == == == OrbitList == == == == == == == == == == == == == == == == == == == == == =\"\"\"\n",
        "    # ------- Method - 2: aggregate_array for obtaining distinct orbitKey -------------------------------------\n",
        "    orbitKeyList = ee.List(sarImgCol_grouped.aggregate_array(\"Orbit_Key\")).distinct().sort()\n",
        "    print(\"orbitKeyList: \", orbitKeyList.getInfo())\n",
        "\n",
        "    # orbitKeyList = ['ASC20']\n",
        "    if sarKmapFlag:\n",
        "        historyImgCol = (S1_filtered.filterDate(ee.Date(fireStartDate).advance(-3, 'month'), fireStartDate)\n",
        "                          .map(set_group_index_4_S1)\n",
        "                          .map(add_RBR)\n",
        "                          .map(sarRescaleToOne)\n",
        "                          )\n",
        "\n",
        "        # printList(historyImgCol.aggregate_array('IMG_LABEL').getInfo(), historyImgCol)\n",
        "\n",
        "# \"\"\"////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\"\"\"\n",
        "# \"\"\" ========================================================== Multispectral Data ==================================================================== \"\"\"\n",
        "# \"\"\"////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\"\"\"\n",
        "\n",
        "if msiQueryFlag:\n",
        "    print(\"\\n---------------- Sentinel-2/Landsat-8 ------------------------\")\n",
        "\n",
        "    # cloudLevel = 50\n",
        "    S2_filters = ee.Filter.And(\n",
        "        ee.Filter.geometry(quaryROI)\n",
        "    )\n",
        "\n",
        "    \"\"\" == == == == == == == == == == == = S2 Data == == == == == == == == == == == ==\"\"\"\n",
        "    def S2_bandScale(img):\n",
        "        return (ee.Image(img).select('B.*').divide(10000)\n",
        "                .addBands(img.select('QA60'))  # keep BQA and cloud bands\n",
        "                .copyProperties(img, img.propertyNames()))\n",
        "\n",
        "\n",
        "    S2_filtered = ee.ImageCollection(ee.ImageCollection(\"COPERNICUS/S2\")\n",
        "                                      .filter(S2_filters)\n",
        "                                      .filterDate(checkStartDate, checkEndDate)\n",
        "                                      .filter(ee.Filter.lt('CLOUD_COVERAGE_ASSESSMENT', cloudLevel))\n",
        "                                      )\n",
        "\n",
        "    S2_grouped = (group_S2_ImgCol(S2_filtered)\n",
        "                  .map(S2_bandScale)\n",
        "                  .map(S2_bandRename)\n",
        "                  .map(updateCloudMaskS2)\n",
        "                  # .map(mask_S2_clouds)\n",
        "                  )\n",
        "\n",
        "    # \"\"\" == == == == == == == == == == == L8 Data == == == == == == == == == == == == == == =\"\"\"\n",
        "\n",
        "    L8_filtered = (ee.ImageCollection(\"LANDSAT/LC08/C01/T1_TOA\")  # TR or TOA\n",
        "                    .filter(S2_filters)\n",
        "                    .filterDate(checkStartDate, checkEndDate)\n",
        "                    .filter(ee.Filter.lt('CLOUD_COVER_LAND', cloudLevel))\n",
        "                    )\n",
        "\n",
        "    L8_grouped = ee.ImageCollection(group_L8_ImgCol(L8_filtered)\n",
        "                                    .map(L8_bandRename)\n",
        "                                    .map(updateCloudMaskL8)\n",
        "                                    # .map(mask_L8_clouds)\n",
        "                                    # .map(add_NBR)\n",
        "                                )\n",
        "\n",
        "    # \"\"\" ======= Merge Multispectral Data =============\"\"\"\n",
        "    msiImgCol = (S2_grouped.merge(L8_grouped)\n",
        "                  # .map(maskClouds)\n",
        "                  )\n",
        "\n",
        "    # printList(msiImgCol.aggregate_array('IMG_LABEL').getInfo(), \"msiImgCol before pntsFilter\")\n",
        "\n",
        "    if pntsFilterFlag:  # apply point filter\n",
        "        msiImgCol = msiImgCol.filter(pntsFilter)\n",
        "\n",
        "    msiMasterDate = fireEvent['S2_Master']\n",
        "    if 'elephant' in fireEvent['name']:\n",
        "        msiMasterDate = fireEvent['L8_Master']\n",
        "\n",
        "    if 'msiExportDates' in fireEvent.keys():\n",
        "        msiImgCol = msiImgCol.filter(ee.Filter.inList(opt_leftField='GROUP_INDEX', opt_rightValue=msiExportDates+[msiMasterDate]))\n",
        "\n",
        "    # printList(msiImgCol.aggregate_array('IMG_LABEL').getInfo(), \"msiImgCol after pntsFilter\")\n",
        "\n",
        "    def msiRescaleToOne(img):\n",
        "        return (img.select('cloud').addBands(\n",
        "                        img.select(['R', 'G', 'B', 'NIR', 'SWIR1', 'SWIR2'])\n",
        "                            .clamp(0, 0.5).unitScale(0, 0.5).float()\n",
        "                        )    #.toUint8()\n",
        "                              # .copyProperties(img, img.propertyNames())\n",
        "                )\n",
        "\n",
        "    msiImgCol = (msiImgCol\n",
        "                    .map(msiRescaleToOne)\n",
        "                    .map(add_NBR)\n",
        "                    .sort('IMG_LABEL', False)\n",
        "                  )\n",
        "    # print(\"bands: {}\".format(msiImgCol.first().bandNames().getInfo()))\n",
        "    printList(msiImgCol.aggregate_array('IMG_LABEL').getInfo(), \"msiImgCol after rescale\")\n",
        "    # printList(L8_grouped.aggregate_array('IMG_LABEL').getInfo(), \"L8_grouped\")\n",
        "    # printList(msiImgCol.aggregate_array('IMG_LABEL').getInfo(), \"msiImgCol\")\n",
        "\n",
        "    print(\"----------------------------------------------------------------------\")\n",
        "\n",
        "# \"\"\"////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\"\"\"\n",
        "# \"\"\" ================================================================= Export MS Data ================================================================= \"\"\"\n",
        "# \"\"\"////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\"\"\"\n",
        "\n",
        "if msiExportFlag:\n",
        "    def add_dNBR(slaveImg):\n",
        "        TH = (ee.Image(0.25).rename('dNBR')\n",
        "              .addBands(ee.Image(0.1).rename('dNBR1'))\n",
        "              )\n",
        "\n",
        "        dNBR = ee.Image(msiMasterImg.subtract(slaveImg).select(['NBR', 'NBR1']).rename(['dNBR', 'dNBR1']))\n",
        "        dNBR_bin = (dNBR.select(['dNBR', 'dNBR1'])\n",
        "                        .gt(TH)\n",
        "                        .multiply(waterMask0)\n",
        "                        .multiply(slaveImg.select('cloud'))\n",
        "                        .multiply(froestMask)\n",
        "                        .rename((['dNBR_bin', 'dNBR1_bin']))\n",
        "                    )\n",
        "\n",
        "        cloud_bin = slaveImg.select('cloud').gt(1)\n",
        "        return (slaveImg\n",
        "                  .addBands(msiMasterImg)\n",
        "                  .addBands(dNBR)\n",
        "                  .addBands(filt_morph(dNBR_bin))\n",
        "                  # .multiply(slaveImg.select('cloud'))\n",
        "                  .copyProperties(slaveImg, slaveImg.propertyNames())\n",
        "                )\n",
        "\n",
        "    ### MS Master Image\n",
        "    msiMasterImg = ee.Image(msiImgCol.filterDate(ee.Date(msiMasterDate), ee.Date(msiMasterDate).advance(1, 'day')).first())\n",
        "\n",
        "    msiImgCol_toExport = (msiImgCol.filterDate(\"2019-10-27\", \"2020-01-11\")\n",
        "                          .map(add_dNBR)\n",
        "                          .sort('IMG_LABEL', False)\n",
        "                  )\n",
        "    print(\"===> MS BANDS: {}\".format(ee.Image(msiImgCol_toExport.first()).bandNames().getInfo()))\n",
        "    printList(msiImgCol_toExport.aggregate_array('IMG_LABEL').getInfo(), \"msiImgCol_toExport\")\n",
        "\n",
        "\n",
        "# \"\"\"////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\"\"\"\n",
        "# \"\"\" ================================================================= Export SAR Data ================================================================ \"\"\"\n",
        "# \"\"\"////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\"\"\"\n",
        "\n",
        "if sarLogRtExportFlag:\n",
        "\n",
        "    if 'sarExportDates' in fireEvent.keys():\n",
        "        sarImgCol_grouped = sarImgCol_grouped.filter(ee.Filter.inList(opt_leftField='GROUP_INDEX', opt_rightValue=sarExportDates))\n",
        "\n",
        "    sarMeanDict = {}\n",
        "    sarStdDict = {}\n",
        "    sarImgCol_toExport = ee.ImageCollection([])\n",
        "    for orbKey in orbitKeyList.getInfo():\n",
        "        # orbKey = 'DSC42'\n",
        "        print(\"==> orbKey checking: \", orbKey)\n",
        "\n",
        "        orbImgCol = ee.ImageCollection(sarImgCol_grouped.filter(ee.Filter.equals('Orbit_Key', orbKey)))\n",
        "\n",
        "        print('orbImgCol: ')\n",
        "        printList(orbImgCol.aggregate_array('IMG_LABEL').getInfo())\n",
        "\n",
        "        print(\"-----------------------------------------------------\\n\\n\")\n",
        "\n",
        "        print('===> orbImgCol: {} <==='.format(orbKey))\n",
        "        printList(orbImgCol.aggregate_array('IMG_LABEL').getInfo())\n",
        "\n",
        "        num = orbImgCol.size().getInfo()\n",
        "        orbImgList = orbImgCol.toList(num)\n",
        "\n",
        "        orbMasterDate = ee.Date(fireEvent[orbKey])\n",
        "        orbMasterImg = ee.Image(\n",
        "            sarImgCol_grouped.filterDate(orbMasterDate, orbMasterDate.advance(2, 'day')).first())\n",
        "\n",
        "        # printList(ee.ImageCollection(orbMasterImg).aggregate_array('IMG_LABEL').getInfo())\n",
        "\n",
        "        # masterImg = ee.Image(orbImgCol.first())\n",
        "\n",
        "        def add_logRt(slaveImg):\n",
        "            meanImg = sarMeanDict[orbKey]\n",
        "            stdDevImg = sarStdDict[orbKey]\n",
        "            logRt = (\n",
        "                ee.Image(meanImg.select(['VV_mean', 'VH_mean', 'RBR_mean']).rename(['VV', 'VH', 'RBR']))\n",
        "                    .subtract(slaveImg)\n",
        "                    .multiply(ee.Image(-1).rename('VV').addBands(ee.Image(-1).rename('VH')).addBands(ee.Image(1).rename('RBR')))\n",
        "                    # ee.Image(orbMasterImg).subtract(slaveImg)\n",
        "                    # .multiply(waterMask.select('water'))\n",
        "                    # .multiply(waterMask.select('ASC'))\n",
        "                    .select(['VV', 'VH', 'RBR'])\n",
        "                    .rename(['VV_logRt', 'VH_logRt', 'RBR_logRt'])\n",
        "                    # .copyProperties(slaveImg, slaveImg.propertyNames())\n",
        "            )\n",
        "\n",
        "            return (slaveImg.addBands(logRt)\n",
        "                    .addBands(meanImg)\n",
        "                    .addBands(stdDevImg))\n",
        "\n",
        "\n",
        "        def add_kmap(logRtImg):\n",
        "            stdDevImg = sarStdDict[orbKey].select(['VV_std', 'VH_std', 'RBR_std']).rename(['VV', 'VH', 'RBR'])\n",
        "            kmap = ee.Image(logRtImg.select(['VV_logRt', 'VH_logRt', 'RBR_logRt']).rename(['VV', 'VH', 'RBR'])\n",
        "                        .divide(stdDevImg)\n",
        "                        .convolve(G_kernel)#.divide(10).float()\n",
        "                        .clamp(-5.0, 5.0).divide(5).float()\n",
        "                        .rename(['kVV', 'kVH', 'kRBR'])\n",
        "                    )\n",
        "\n",
        "            # k = kmap.expression(\n",
        "            #     \"sqrt(b('kVV')*b('kVV')+b('kVH')*b('kVH'))*b('kVV')/sqrt(b('kVV')*b('kVV'))\")\\\n",
        "            #         .convolve(G_kernel).rename('kmap')\n",
        "            return logRtImg.addBands(kmap)\n",
        "\n",
        "\n",
        "        \"\"\" Compute mean and stdDev with the stdDev of historical time series for one given orbit\"\"\"\n",
        "        orbHistoryImgCol = historyImgCol.filter(ee.Filter.equals('Orbit_Key', orbKey))\n",
        "\n",
        "        printList(orbHistoryImgCol.aggregate_array('IMG_LABEL').getInfo(), 'orbHistoryImgCol')\n",
        "\n",
        "        sarMeanDict[orbKey] = ee.Image(orbHistoryImgCol.reduce(ee.Reducer.mean())\n",
        "                .setMulti({'IMG_LABEL': 'SAR_MEAN_{}'.format(orbKey)}))\n",
        "\n",
        "        sarStdDict[orbKey] = ee.Image(orbHistoryImgCol.reduce(ee.Reducer.stdDev())\n",
        "                .select(['VV_stdDev', 'VH_stdDev', 'RBR_stdDev'])\n",
        "                .rename(['VV_std', 'VH_std', 'RBR_std'])\n",
        "                .setMulti({'IMG_LABEL': 'SAR_STD_{}'.format(orbKey)}))\n",
        "\n",
        "        # print(\"Std Bands: {}\".format(sarStdDict[orbKey].bandNames().getInfo()))\n",
        "\n",
        "        logRtImgCol = (orbImgCol.map(add_logRt)\n",
        "                .map(add_kmap)\n",
        "            )\n",
        "        sarImgCol_toExport = sarImgCol_toExport.merge(logRtImgCol)\n",
        "\n",
        "\n",
        "    \"\"\" Export polys \"\"\"\n",
        "    # polyDate = ee.Date(\"2019-12-27\")\n",
        "    # burnRef = ee.Image(sarImgCol_toExport.filterDate(polyDate, polyDate.advance(1, 'day')).first())\n",
        "    # print(\"burnRef bandnames: {}\".format(burnRef.bandNames().getInfo()))\n",
        "    # # exportPolyToAsset(burnRef.select('kRBR_bin1').clip(roi))\n",
        "    # exportImageToAsset(burnRef.clip(roi))\n",
        "\n",
        "    binThreshold = 1\n",
        "    BAND2BIN = ['kVH', 'kVV', 'kRBR']\n",
        "    binBandNameList = []\n",
        "    for band in BAND2BIN:\n",
        "        binBandNameList.append(\"{}_bin\".format(band))\n",
        "\n",
        "    def imgBinarize(img):\n",
        "        # binThreshold = 1\n",
        "        imgBin = (img.select(BAND2BIN).gt(binThreshold / 5.0)\n",
        "                  .multiply(waterMask.select('water'))\n",
        "                  .multiply(waterMask.select(orbKey[:3]))\n",
        "                  .multiply(froestMask)\n",
        "                  .rename(binBandNameList)\n",
        "                  )\n",
        "        return img.addBands(filt_morph(imgBin))\n",
        "\n",
        "    # def changeImgLabel(img):\n",
        "    #     return img.setMulti({'IMG_LABEL': ee.String(\"SAR_{}\".format(img.get('IMG_LABEL').getInfo()))})\n",
        "\n",
        "    print(\"SAR BANDS: {}\".format(sarImgCol_toExport.first().bandNames().getInfo()))\n",
        "    sarImgCol_toExport = sarImgCol_toExport.map(imgBinarize).sort('IMG_LABEL', False)\n",
        "    printList(ee.ImageCollection(sarImgCol_toExport).aggregate_array('IMG_LABEL').getInfo(), 'sarImgCol_toExport')\n",
        "\n",
        "    # Multispectral Data\n",
        "    msiImgCol_toExport = (msiImgCol.filterDate(\"2019-10-27\", \"2020-01-11\")\n",
        "                          .map(add_dNBR)\n",
        "                          .sort('IMG_LABEL', False)\n",
        "                  )\n",
        "    print(\"===> MS BANDS: {}\".format(ee.Image(msiImgCol_toExport.first()).bandNames().getInfo()))\n",
        "    printList(msiImgCol_toExport.aggregate_array('IMG_LABEL').getInfo(), \"msiImgCol_toExport\")\n",
        "\n",
        "print(\"------------------------ Earth Engine Preprocessing Finished -----------------------------------\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDflxGcyhk_c",
        "colab_type": "text"
      },
      "source": [
        "### 2.3 Visualize Images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9c29yYrhlKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MSI = msiImgCol_toExport.filterDate(\"2019-12-26\", \"2019-12-28\").first()\n",
        "SAR = sarImgCol_toExport.filterDate(\"2019-12-27\", \"2019-12-28\").first()\n",
        "\n",
        "mapid = MSI.select('dNBR1_bin').getMapId({'min': 0, 'max': 1})\n",
        "map = folium.Map()\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='dNBR1',\n",
        "  ).add_to(map)\n",
        "\n",
        "mapid = SAR.select('kRBR_bin').getMapId({'min': 0, 'max': 1})\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='kRBR',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42JU4kcAah0-",
        "colab_type": "text"
      },
      "source": [
        "# Step 3: Export EO Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_UVFifpnWsK",
        "colab_type": "text"
      },
      "source": [
        "##### 3.1 Define Export Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA3xnFCBYOTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_imgCol_export_to_cloud_classBalanced(imgCol, classBand, N=100, KERNEL_SIZE=256, toDriveFolder=\"Sydney_NRT\"):\n",
        "    print(\"------------------------- Download Start ... ----------------------------------\")\n",
        "    downLoadList = (imgCol).aggregate_array('IMG_LABEL').getInfo()\n",
        "    printList(downLoadList, 'to_cloud_classBalanced')\n",
        "\n",
        "    # KERNEL_SIZE = 256R\n",
        "    n = 30\n",
        "    SCALE = 100\n",
        "    print(\"Total Number of SEED : {} in {}m resolution\".format(n, SCALE))\n",
        "    # N = 100\n",
        "    list = ee.List.repeat(1, KERNEL_SIZE)\n",
        "    lists = ee.List.repeat(list, KERNEL_SIZE)\n",
        "    kernel = ee.Kernel.fixed(KERNEL_SIZE, KERNEL_SIZE, lists)\n",
        "\n",
        "    num = imgCol.size().getInfo()\n",
        "    imgColList = imgCol.toList(num)\n",
        "\n",
        "    for i in range(0, num):\n",
        "        img = ee.Image(imgColList.get(i))\n",
        "        imgName = img.get('IMG_LABEL').getInfo().replace(\":\", '')\n",
        "  \n",
        "        arrays = img.neighborhoodToArray(kernel)\n",
        "        featCol = ee.FeatureCollection([])\n",
        "        for SEED in range(n):\n",
        "            # print(\"SEED: {}\".format(SEED))\n",
        "            pntCol = (img.select(classBand).rename('class').toInt().addBands(ee.Image.pixelLonLat())\n",
        "                .stratifiedSample(\n",
        "                    region=roi,\n",
        "                    numPoints=int(N/n),\n",
        "                    classBand='class',\n",
        "                    scale=SCALE,\n",
        "                    seed=SEED,\n",
        "                    dropNulls=True,\n",
        "                    tileScale=8\n",
        "                ).map(buildGeometryPoint)\n",
        "            )  \n",
        "\n",
        "            tmpfeatCol = arrays.sampleRegions(\n",
        "              collection=pntCol,\n",
        "              scale=SCALE,\n",
        "              # properties=FEATURES,\n",
        "              tileScale=8\n",
        "            )\n",
        "\n",
        "            print(\"SEED {}: {}\".format(SEED, tmpfeatCol.size().getInfo()))\n",
        "            featCol = featCol.merge(tmpfeatCol)\n",
        "\n",
        "        desc = \"trainPatches_{}_{}m_ks{}_N{}\".format(imgName, SCALE, KERNEL_SIZE, featCol.size().getInfo())\n",
        "        print(\"desc: {}\".format(desc))\n",
        "        task = ee.batch.Export.table.toDrive(\n",
        "            collection=featCol,\n",
        "            description=desc,\n",
        "            # bucket=BUCKET,\n",
        "            folder=toDriveFolder,\n",
        "            fileNamePrefix=desc,\n",
        "            fileFormat=\"TFRecord\",\n",
        "            selectors=FEATURES\n",
        "        )\n",
        "\n",
        "        task.start()\n",
        "        check_export_task(task, desc)\n",
        "        return featCol\n",
        "\n",
        "# printList(ee.ImageCollection(sarImgCol_toExport).aggregate_array('IMG_LABEL').getInfo(), 'sarImgCol_toExport')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abp6Vrf8kiC9",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Export Data to Drive/CloudStorge "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KfmIpv4kXtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FEATURES = [\n",
        "          'VV', 'VH', 'RBR',\n",
        "          'VV_mean', 'VH_mean', 'RBR_mean',\n",
        "          'VV_std', 'VH_std', 'RBR_std',\n",
        "          # 'VV_logRt', 'VH_logRt', 'RBR_logRt',\n",
        "          # 'kVV', 'kVH', 'kRBR', 'kmap',\n",
        "          'kRBR_bin', 'ref'\n",
        "\n",
        "          # 'NIR', 'SWIR1', 'SWIR2',\n",
        "          # 'NIR_1', 'SWIR1_1', 'SWIR2_1',\n",
        "          # 'dNBR1_bin'\n",
        "          ]\n",
        "\n",
        "\n",
        "\"\"\" to cloudStorage \"\"\"\n",
        "BUCKET = \"wildfire-unet\"\n",
        "FOLDER = 'Sydney_NRT'\n",
        "\n",
        "msiImg =  msiImgCol_toExport.filterDate(\"2019-12-26\", \"2019-12-27\").first()\n",
        "sarImg = sarImgCol_toExport.filterDate(\"2019-12-27\", \"2019-12-28\").first()\n",
        "ref = ee.Image(\"users/omegazhangpzh/Sydney_Ref/20191227_ASC9\").unmask().rename('ref')\n",
        "mrgImg_toExport = (\n",
        "          # msiImg\n",
        "          sarImg\n",
        "          # .addBands(msiImg)\n",
        "            .addBands(ref)\n",
        "        ).select(FEATURES)\n",
        "\n",
        "def printBandNames(img):\n",
        "  bandList = img.bandNames().getInfo()\n",
        "  for i in range(0, len(bandList), 3):\n",
        "    print(\"{}\\n\".format(bandList[i:i+3]))\n",
        "\n",
        "printBandNames(mrgImg_toExport)\n",
        "# print(\"mrgImg bandnames: {}\".format(mrgImg_toExport.bandNames().getInfo()))\n",
        "\n",
        "\n",
        "sarImgCol_toExport_Test = ee.ImageCollection([mrgImg_toExport])\n",
        "\n",
        "# batch_imgCol_export_to_cloud(sarImgCol_toExport_Test, N=1000, KERNEL_SIZE=256, toDriveFolder=FOLDER)\n",
        "featCol = batch_imgCol_export_to_cloud_classBalanced(imgCol=sarImgCol_toExport_Test, classBand='ref', N=1000, KERNEL_SIZE=128, toDriveFolder=\"Sydney_NRT\")\n",
        "print(\"Exported PropertyNames: {}\".format(featCol.propertyNames().getInfo())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aifhKNEcmFhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}